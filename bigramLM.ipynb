{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/bzzt/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('corpus.txt', 'r') as fil:\n",
    "    inp_data = fil.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i stand here i feel empty\n",
      "[1045, 3233, 2182, 1045, 2514, 4064]\n",
      "['i', 'stand', 'here', 'i', 'feel', 'empty']\n"
     ]
    }
   ],
   "source": [
    "def get_tokens(seq):\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    return tokenizer.convert_tokens_to_ids(tokenizer.tokenize(seq))\n",
    "\n",
    "def get_seq(ids):\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    return tokenizer.convert_ids_to_tokens(ids)\n",
    "\n",
    "print(inp_data[:25])\n",
    "tkn = get_tokens(inp_data[:25])\n",
    "seq = get_seq(tkn)\n",
    "print(tkn)\n",
    "print(seq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2034, 6926, 1024, 2077, 2057, 10838, 2151, 2582, 1010, 2963]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trf_data = get_tokens(inp_data)\n",
    "trf_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['first',\n",
       " 'citizen',\n",
       " ':',\n",
       " 'before',\n",
       " 'we',\n",
       " 'proceed',\n",
       " 'any',\n",
       " 'further',\n",
       " ',',\n",
       " 'hear']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst_data = get_seq(trf_data)\n",
    "lst_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_tkn = max(trf_data) + 1\n",
    "coeff_mat = np.zeros((max_tkn, max_tkn), dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t1, t2 in zip(trf_data, trf_data[1:]):\n",
    "    coeff_mat[t1, t2] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "p  = coeff_mat[2034]\n",
    "p = p/p.sum()\n",
    "sample = np.random.choice(len(p), p=p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":\n",
      ":\n",
      "citizen\n",
      "murderer\n",
      "lord\n",
      ",\n",
      "'\n",
      "servant\n",
      "gentleman\n",
      "murderer\n"
     ]
    }
   ],
   "source": [
    "def genrate(seq_ln):\n",
    "    idx = 101\n",
    "    for i in range(seq_ln):\n",
    "        p  = coeff_mat[2034]\n",
    "        p = p/p.sum()\n",
    "        idx = np.random.choice(len(p), p=p)\n",
    "        print(get_seq(idx))\n",
    "genrate(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "class BigramLM:\n",
    "    def get_tokens(self, seq):\n",
    "        tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "        return tokenizer.convert_tokens_to_ids(tokenizer.tokenize(seq))\n",
    "\n",
    "    def get_seq(self, ids):\n",
    "        tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "        return tokenizer.convert_ids_to_tokens(ids)\n",
    "    \n",
    "    def create_matrix(self, tokens):\n",
    "        max_tkn = max(trf_data) + 1\n",
    "        coeff_mat = np.zeros((max_tkn, max_tkn), dtype=np.int32)\n",
    "        for t1, t2 in zip(tokens, tokens[1:]):\n",
    "            coeff_mat[t1, t2] += 1\n",
    "        return coeff_mat\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.token_data = self.get_tokens(data)\n",
    "        self.coeff_mat = self.create_matrix(self.token_data)\n",
    "    \n",
    "    def genrate(self, seq_ln):\n",
    "        idx = 101\n",
    "        for i in range(seq_ln):\n",
    "            p  = coeff_mat[2034]\n",
    "            p = p/p.sum()\n",
    "            idx = np.random.choice(len(p), p=p)\n",
    "            print(get_seq(idx))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('corpus.txt', 'r') as fil:\n",
    "    inp_data = fil.read()\n",
    "bgram = BigramLM(inp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin\n",
      "senator\n",
      "senator\n",
      "murderer\n",
      "senator\n",
      "servant\n",
      "murderer\n",
      "senator\n",
      "serving\n",
      ":\n"
     ]
    }
   ],
   "source": [
    "bgram.genrate(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1045]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_tokens(\"i\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day\n",
      "entry\n",
      "few\n",
      "felt\n",
      "time\n",
      "trim\n",
      "kiss\n",
      "starting\n",
      "time\n",
      "attempt\n"
     ]
    }
   ],
   "source": [
    "class BigramLM:\n",
    "    def get_tokens(self, seq):\n",
    "        tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "        return tokenizer.convert_tokens_to_ids(tokenizer.tokenize(seq))\n",
    "\n",
    "    def get_seq(self, ids):\n",
    "        tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "        return tokenizer.convert_ids_to_tokens(ids)\n",
    "    \n",
    "    def create_matrix(self, tokens):\n",
    "        max_tkn = max(tokens) + 1\n",
    "        coeff_mat = np.zeros((max_tkn, max_tkn), dtype=np.int32)\n",
    "        for t1, t2 in zip(tokens, tokens[1:]):\n",
    "            coeff_mat[t1, t2] += 1\n",
    "        return coeff_mat\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.token_data = self.get_tokens(data)\n",
    "        self.coeff_mat = self.create_matrix(self.token_data)\n",
    "    \n",
    "    def genrate(self, seq_ln, strt = 1045):\n",
    "        idx = strt\n",
    "        for i in range(seq_ln):\n",
    "            p  = self.coeff_mat[idx]\n",
    "            p = p/p.sum()\n",
    "            idx = np.random.choice(len(p), p=p)\n",
    "            print(self.get_seq(idx))\n",
    "\n",
    "        \n",
    "with open('corpus.txt', 'r') as fil:\n",
    "    inp_data = fil.read()\n",
    "bgram = BigramLM(inp_data)\n",
    "bgram.genrate(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2051]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_tokens('time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bzzt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
